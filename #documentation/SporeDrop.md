# SporeDrop Chatbot Module â€“ Reference Guide

---

## ğŸ”¹ Purpose

This Go module acts as a **middleware service** between a chat client (e.g., Discord) and the **Mistral LLM API**, enabling contextual, rate-limited interactions via HTTP requests. It supports:

* In-memory user-specific message context
* JSON-based chat inputs and outputs
* Call delegation to a hosted Mistral endpoint
* Rate-limiting per user to prevent abuse

---

### ğŸ“ Core Components

#### 1. **Dependencies**

```go
"github.com/gin-gonic/gin"
"github.com/joho/godotenv"
```

* `gin`: lightweight web framework for routing HTTP requests
* `godotenv`: loads environment variables from `.env` file

---

### ğŸ“¦ Data Structures

#### â¤ `ChatInput`

```go
type ChatInput struct {
	UserID  string `json:"user"`
	Message string `json:"message"`
}
```

* Represents the incoming request payload from a client (e.g., a Discord message)
* `UserID` is required to track memory per-user

#### â¤ `ChatOutput`

```go
type ChatOutput struct {
	Reply string `json:"reply"`
}
```

* Encapsulates the chatbotâ€™s textual response

#### â¤ `Message`

```go
type Message struct {
	Role    string `json:"role"`     // "user", "assistant", "system"
	Content string `json:"content"`  // actual message text
}
```

* Used for memory and LLM API payloads
* Stored and sent in role-based history for context

#### â¤ `MistralRequest` & `MistralResponse`

```go
type MistralRequest struct {
	Messages    []Message
	Temperature float32
	Stream      bool
}
```

* Mistral-compatible prompt object using user context

```go
type MistralResponse struct {
	Choices []struct {
		Message struct {
			Content string
		}
	}
}
```

* Minimal structure to parse a response from Mistral

---

### ğŸ—‚ Global State

#### â¤ `memoryStore`

```go
var memoryStore = make(map[string][]Message)
```

* Stores per-user chat memory in memory, used as conversation context

#### â¤ `lastSeen`

```go
var lastSeen = make(map[string]time.Time)
```

* Stores timestamp of each user's last message to throttle frequency

---

### âš™ï¸ Initialization Logic

#### â¤ `init()`

```go
func init() {
	godotenv.Load()
}
```

* Loads `.env` values (e.g., `MISTRAL_URL`, `MISTRAL_TOKEN`, `PORT`)

#### â¤ `main()`

```go
router.POST("/chat", handleChat)
```

* Starts a web server on `PORT` (default: 8080)
* Defines one endpoint: `POST /chat`

---

### ğŸš¦ Endpoint Handler

#### â¤ `handleChat(c *gin.Context)`

Processes all chat events. Key steps:

1. âœ… Validate request body & `UserID`
2. ğŸš« Apply 3-second per-user rate limit via `lastSeen`
3. ğŸ§  Append user's message to their memory
4. ğŸ¤– Send memory to Mistral API and retrieve reply
5. ğŸ“¥ Store assistant reply in memory
6. ğŸ” Return reply as JSON

---

### ğŸ§¹ Utility: Trim Memory

#### â¤ `trimMemory()`

```go
func trimMemory(messages []Message, limit int) []Message
```

* Keeps only the last `limit` messages per user
* Used to prevent memory overgrowth

---

### ğŸ¤– LLM Call

#### â¤ `callMistral(userID string)`

1. Trims user memory to 20 messages
2. Constructs a `MistralRequest`
3. Makes an authenticated `POST` request to Mistral API
4. Parses `Choices[0].Message.Content` as final reply

---

### ğŸ“„ .env Required Variables

Make sure the following exist in your `.env`:

```
PORT=8080
MISTRAL_URL=https://api.mistral.ai/v1/chat/completions
MISTRAL_TOKEN=your_mistral_api_key
```

---

### ğŸ§± Example Request

#### Request

```json
POST /chat
Content-Type: application/json

{
  "user": "123456",
  "message": "What's the weather like on Mars?"
}
```

#### Response

```json
{
  "reply": "Itâ€™s dry and dusty as usual. Bring sunscreen!"
}
```

---

### ğŸ” Protections Implemented

| Feature        | Behavior                            |
| -------------- | ----------------------------------- |
| Rate Limiter   | 3 seconds per user (via `lastSeen`) |
| Memory Control | Trimmed to last 20 messages         |
| Input Check    | Rejects if `UserID` is missing      |

---
